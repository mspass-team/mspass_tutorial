{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedc9bb5-b959-4b92-a8cb-bfbcc9056287",
   "metadata": {},
   "source": [
    "# HPC exercise preparation\n",
    "## Objective\n",
    "Session 2 of the class will involve work her on GeoLab and on the HPC machine at the Texas Advanced Computer Center (TACC) called frontera.   This notebook has no python code but contains instructions needed for that exercise.  Instructions that can executed somewhere else by a cut-and-paste operation are in \"raw\" boxes.  If they require substitutions the required substitutions will be highlighted in italics.\n",
    "\n",
    "## Setup\n",
    "You will want to have two windows running to do this exercise effectively.   \n",
    "1.  Here on GeoLab launch a new \"Terminal\" tab from the Launcher tab.  I will refer to this window in this document as **Terminal A**.\n",
    "2.  On your local compouter launch the \"Terminal\" application for your platform.   For Macs and Linux machines that is the name of the application.  For windows you may need a special application like putty capable of terminal interaction with a remote host that supports ssh.   I fill refer to this window in this document as **Terminal B**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a72c8-b9a1-4ff1-b762-d80ab215d7b4",
   "metadata": {},
   "source": [
    "## Connect to frontera\n",
    "In **Terminal B** use the ssh command to connect to frontera.  You should have done a test of that functionality previously using instructions we sent you earlier.  If you haven't done that you will be way behind for this session and may have be a passive participant and work on the frontera exercise on your own time. \n",
    "```bash\n",
    "ssh myusername@frontera.tacc.utexas.edu\n",
    "```\n",
    "Note that you need to change *myusername* to your own user name on frontera.\n",
    "\n",
    "## Copy data files\n",
    "Once you are on frontera issue this command:\n",
    "```bash\n",
    "cd $SCRATCH\n",
    "pwd\n",
    "```\n",
    "We want to do this exercise on the \"scratch\" file system to avoid file quota issues we would hit if you used your \"home\" directory, which is where you land when you login with ssh.  You will use the output of pwd below.\n",
    "\n",
    "Next you need to copy two directories containing shared data files we will need for this exercise.   We are doing a copy rather than used a shared directory to simplify configuration.  The data set is not tiny but it is not enormoous either so this will not stress this huge cluster.  Cut-and-paste this pair of commands into **Terminal B**.\n",
    "```bash\n",
    "cp -r /scratch1/04465/pavlis/ES2025/exports .        # directory with preconstructed database collections \n",
    "cp -r /scratch1/04465/pavlis/ES2025/wf .             # directory of miniseed files of raw data to be processed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a5745-8de0-4d16-92e7-54ddcffd8d9f",
   "metadata": {},
   "source": [
    "## Edit configuration file\n",
    "In jupyter lab open the file tacc_files/HPCClusterLauncher.yaml.  As usual you need only browse to that directory and double click that file.  That puts you in a crude text file editor.   \n",
    "\n",
    "This file is a simple text file in the \"yaml\" (Yet Another Markup Language) format.  Two key warnings are:  (1) don't alter any of the keys (name to the left of : symbols) and (2) indents are significant just like in python.\n",
    "\n",
    "For this exercise you will need to edit the value (right hand side) of several values in this configuration file.   The main changes are directory locations defined by four attribute:  `working_directory`, `log_directory`, `database_directory`, and `worker_directory`.   The default jupyter text editor has no global search-replace function, but that is essentially what you need here.  In this entire file you need to change all occurrences of `/scratch1/04465/pavlis/ES2025` to the output of the `pwd` command in **Terminal B** you created a few minutes ago - i.e.  your top level directory in scratch.  \n",
    "\n",
    "Note that the key `container_run_args` also contains the magic string `/scratch1/04465/pavlis/ES2025` that also needs to be changed to your top level scratch directory.\n",
    "\n",
    "The other parameters in this file will be left alone but I will review what they do briefly while you complete this setup.   We will pause here until everyone has that finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b087e8a-b29d-48aa-89e4-9fef17744a45",
   "metadata": {},
   "source": [
    "## Copy tacc_files to frontera\n",
    "Once you have all the files edited correctly you will need to transfer the copy you edited here on GeoLab to frontera.   In **Terminal A** make sure you cd to the proper directory.   If you clone the mspass_tutorial directory normally you should be able to get there with a cut-and-paste to **Terminal A** of the following:\n",
    "```bash\n",
    "cd\n",
    "cd mspass_tutorial/Earthscope2025/tacc_files\n",
    "```\n",
    "Then run this command changing *myscratch_directory* to the same pwd output you used in editing the configuration file (i.e. your top level scratch directory) above and changing *myusername* to the user name you were assigned for frontera.  Note you will be prompted for a password and dual authentication just like when you logged in to **Terminal B**.\n",
    "```bash\n",
    "scp * myusername@frontera.tacc.utexas.edu:myscratch_directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3f792",
   "metadata": {},
   "source": [
    "## Import the database \n",
    "Now, we have everything prepared for running MsPASS on Frontera. In **Terminal B**, please make sure you are in the directory that you have all the files copied. We not submit the database import job with the following command:\n",
    "```bash\n",
    "sbatch dbimport.job\n",
    "```\n",
    "This job will run for a couple minutes to import the database that will be used for the large Receiver Function processing job next. It executes the `run_mongoimport.py` Python script. You can use the following command to check the status of the job:\n",
    "```bash\n",
    "squeue --me\n",
    "```\n",
    "If the job is finished, you should see a file created with the name `mspass.o????`, where `????` is the job ID that matches the one in the outputs of the `sbatch` and `squeue` commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be1123",
   "metadata": {},
   "source": [
    "## Run the Receiver Function workflow\n",
    "Here we will launch the big job that runs the Receiver Function processing. Submit the job with:\n",
    "```bash\n",
    "sbatch processdata.job\n",
    "```\n",
    "This job will run the `RFprocessing.ipynb` notebook in the batch mode. You can check the status of the run again with the `squeue --me` command. This job should run for 43 minutes, and we can check the output in the `mspass.o????` file when it finishes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
