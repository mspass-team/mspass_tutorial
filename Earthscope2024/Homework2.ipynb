{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d72ab58-ef93-4391-ab1b-6e5227a4409a",
   "metadata": {},
   "source": [
    "# Session 2 Assignment Workbook\n",
    "## Part 1:  In class work for session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704f13a-f71b-48f7-b53d-0720fbfb066d",
   "metadata": {},
   "source": [
    "*Information*.  Enter your name an institution here so we can identify your submission:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a05f2-16ec-40e8-bcf9-78902844c8e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "376e3a7d-6cb6-4e79-8bf9-043271f49269",
   "metadata": {},
   "source": [
    "Run this standard box to create an instance of MsPASS client and then instantiates and a MsPASS database handle.   In jargon discussed today db will hold an instance of the MongoDB client used to interact with the MongoDB server running GeoLAB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7954d155-8c0b-4bb7-b43b-5ef2fdf303bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mspasspy.db.database import Database\n",
    "import mspasspy.client as msc\n",
    "mspass_client=msc.Client(database_name='Earthscope2024')\n",
    "db = mspass_client.get_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60acb26-fa24-4996-8118-e7a656fc4e9f",
   "metadata": {},
   "source": [
    "### Work Session 1\n",
    "\n",
    "*Question 1*.   Discuss the output of the timing test you should have just run.  Are the numbers consistent with the factors discussed in the tutorial notebook?   If so how are they consistent?  If they differ, suggest why they might differ?   In both cases a starting point is to state your understanding of what has to happen in any given call to `db.save_data`? (Note a completely wrong answer will get you credit for this question, we need to test your understanding and correct misconceptions that are pretty much guaranteed in class this size.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfcbc0-85df-4494-97d4-6c3aa89dce88",
   "metadata": {},
   "source": [
    "*Question 1 answer*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790d139-f0aa-4f3d-97a1-0a858ae7fd27",
   "metadata": {},
   "source": [
    "### Work Session 2\n",
    "\n",
    "*Question 2*.  Complete each of the code boxes below by setting the value of the \"query\" symbol based on the requirement given by the comment.  The first box is an example to clarify that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1fe01-2baf-41f0-8257-131bdde17cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# How many Seismogram objects are in this data set for station 125A\n",
    "query={'sta' : '125A'}\n",
    "n = db.wf_Seismogram.count_documents(query)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afaf335-bca5-4363-a713-67045930039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many BHZ waveforms are indexed by the wf_TimeSeries collection?\n",
    "query=?\n",
    "n = db.wf_Seismogram.count_documents(query)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf2c32-eb8c-4124-941c-6603d00d2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many stations defined in site are located south of 37 degrees N\n",
    "query=?\n",
    "n = db.site.count_documents(query)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ae6a8-cd3d-43e4-8373-0d9b60623056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and print the channel document for station Z31A and channel BHE\n",
    "query=?\n",
    "n = db.channel.count_documents(query)\n",
    "print(\"Number of channel documents for query=\",query,\" is \",n)\n",
    "doc = db.channel.find_one(query)\n",
    "print(\"find_one result\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb221d9c-be01-4ce0-b9cd-9f0b985fc51d",
   "metadata": {},
   "source": [
    "## Part 2:  Homework\n",
    "You can complete the following at your leisure.  A completed notebook must ultimately be submitted to receive a certificate for the course, but much less will be expected if you submit them by the deadline before session 2.   We want to see your answers to address any questions and head of any misconceptions we might have created in session 1 at the start of session 2.  You will also get the equivalent of one free, full credit answer if you submit your answer prior to deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9141003-ddbe-475f-ba66-2ef4c8c9d70c",
   "metadata": {},
   "source": [
    "*Question 4*.  Read through text in the entire Session1.ipynb notebook INCLUDING all links to sections of the MsPASS User's Manual.  For links to docstrings \"read\" means a internet \"read\" which is what we used to call skimming. Answer the following even if the answer is no to get credit for this question. \n",
    "\n",
    "a.  Did you read the entire notebook?\n",
    "\n",
    "b.  Do you have any questions?\n",
    "\n",
    "c.  Do you have any constructive criticism of content that we can use to improve the class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21620885-57e3-4048-af55-4681fe925ca3",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "Print a projection of the entire content of the source collection in tabular form using pandas.   The table should include only the following attributes: lat, lon, depth, time, magnitude.   (Note it is wrong if the table has the \"_id\" field included.)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5770803-1b7a-4d97-9183-3d19e7b8ad97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "077873a8-978c-46a8-8504-fe8737ce2620",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "Modify the output to print the origin times with obspy's UTCDateTime.  i.e. convert the times to a human readable form. Also produce the output in time order from earliest to latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ab269-583d-45d4-b91f-722707c60a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca9331d-4d2a-4603-acae-9ca3e4eafeaf",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Alter your previous python code to only include sources with an origin time between Jan. 1, 2011 and the end of March (Mar. 31, 2011).   (Hint:   MsPASS stores time as a unix epoch time which can be obtained from a UTCDateTime object with the \"timestamp\" method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a96fe7-fba3-4956-ad87-8bb59603ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2208032b-5a48-4c5c-8319-075bec55bab2",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Construct a query to count the number of documents in wf_miniseed and wf_Seismogram for each of the sources defined in the source collection.   The answer should be printed as a table with these fields:  source_id, number of documents in wf_miniseed, number of documents in wf_Seismogram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396013a-c8bc-4901-a600-021faacf4609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "695afbb8-deea-4fd3-bde6-60b6c37e3759",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "This is a full exercise in using a query to assemble a plot a particular set of data using a database query.  Construct (in this order) the following:\n",
    "1. Construct a query to limit the data return to the following from wf_TimeSeries:  (a) BHZ channels, (b) station names that begin with \"Z\", and (c) recordings of the Tohoku mainshock (Hint:  the easiest way to do this to use the \"dfile\" field as the data are assembled in common source gather files.)\n",
    "2. Apply the query to wf_TimeSeries similar to examples we did during the class.\n",
    "3. Run the `read_data` method of `Database` to construct a `TimeSeriesEnsemble` object that is the result of the query.\n",
    "4. Apply the scale function to the ensemble as we did before plotting in Session1.ipynb.\n",
    "5. Plot the ensemble with `SeismicPlotter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462efb7f-9d72-45d6-aa2f-5a55d4882449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
